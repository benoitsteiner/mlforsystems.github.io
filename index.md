---
title: Annoucement
workshop_name: neurips2019
site_description: Workshop on ML for Systems at NeurIPS 2019, December 13-14th
site_title: ML For Systems
---

<div class="inner clearfix">
	<section class="main-content overview_section">
		<p>
      Compute requirements are growing at an exponential rate<sup>1</sup>sup>, and optimizing these computer systems often involves complex high-dimensional combinatorial problems. Yet, current methods rely heavily on heuristics. Very recent work has outlined a broad scope where machine learning vastly outperforms these traditional heuristics, including scheduling<sup>2,12</sup>sup>, data structure design<sup>3,9</sup>sup>, microarchitecture<sup>4</sup>sup>, compilers<sup>5,8</sup>sup>, circuit design<sup>7,10</sup>sup>, and the control of warehouse scale computing systems<sup>6</sup>sup>. In order to continue to scale these computer systems, new learning approaches are needed. The goal of this workshop is to develop novel machine learning methods to optimize and accelerate software and hardware systems. 
	  <p>
      The main objective of this workshop is to expand upon this recent work and build a community focused on using machine learning in computer architecture and systems problems. We seek to improve the state of the art in the areas where learning has already proven to perform better than traditional heuristics, as well as expand to new areas throughout the system stack such as hardware/circuit design and operating/runtime systems.
	  </p>
	  <p>
      We expect this year to improve the state of the art in areas where learning has already proven to outperform traditional heuristics. We also expect to expand into new areas throughout the systems stack, such as computer architecture and operating/runtime systems, and incorporate new ML topics like relational learning. Given that the community is larger than last year, for NeurIPS 2019, we intend to foster more discussion through breakout sessions. The interdisciplinary nature of this area makes NeurIPS an ideal venue for 
	  </p>
		<p>
			By forming a community of academic and industrial researchers who are excited about this area, we seek to build towards intelligent, self optimizing systems and answer questions such as: How do we generate and share high quality datasets that span the layers of the system stack? Which learned representations best represent code performance and runtime? Which simulators and simulation methodologies provide a tractable proving ground techniques like reinforcement learning?
		</p>
		<p>
			To this end, the target audience for this workshop includes a wide variety of attendees from state-of-the-art researchers in machine learning to domain experts in computer systems design. We have invited a <a href="#speakers">broad set of expert speakers</a> to present the potential for impact of combining deep learning research with computer systems. We hope that by providing a formal venue for researchers from both fields to meet and interact, that the result will include both fundamental research in ML as well as real-world impact to computer systems design and implementation.
		</p>
		<p>
			The workshop hosted 6 speakers and we invited researchers to submit relevant papers through our <a href="/neurips2018/call_for_papers.html">call for papers</a>. The speakers, and potentially other relevant stakeholders, are invited to participate in a panel discussion to end the workshop. See the <a href="/schedule.html">schedule</a>.
		</p>
		<ul class="footnotes">
      <li><sup>1</sup>sup><a href="https://openai.com/blog/ai-and-compute/">AI and Compute</a></li>
      <li><sup>2</sup>sup><a href="https://arxiv.org/pdf/1706.04972.pdf">Device Placement Optimization with Reinforcement Learning</a></li>
      <li><sup>3</sup>sup><a href="https://arxiv.org/abs/1712.01208">The Case for Learned Index Structures</a></li>
      <li><sup>4</sup>sup><a href="https://arxiv.org/pdf/1803.02329.pdf">Learning Memory Access Patterns</a></li>
      <li><sup>5</sup>sup><a href="https://ieeexplore.ieee.org/document/8091247/?reload=true">End to End Deep Learning of Optimization Heuristics</a></li>
      <li><sup>6</sup>sup><a href="https://deepmind.com/blog/deepmind-ai-reduces-google-data-centre-cooling-bill-40/">DeepMind AI Reduces Google Data Centre Cooling Bill by 40%</a></li>
      <li><sup>7</sup>sup><a href="https://arxiv.org/pdf/1903.00614.pdf">GAP: Generalizable Approximate Graph Partitioning Framework</a></li>
      <li><sup>8</sup>sup><a href="https://arxiv.org/abs/1808.07412">Ithemal: Accurate, Portable and Fast Basic Block Throughput Estimation using Deep Neural Networks</a></li>
      <li><sup>9</sup>sup><a href="https://arxiv.org/abs/1808.03196">Learning to Optimize Join Queries With Deep Reinforcement Learning</a></li>
      <li><sup>10</sup>sup><a href="https://arxiv.org/abs/1812.02734">Learning to Design Circuits</a></li>
      <li><sup>11</sup>sup><a href="https://arxiv.org/abs/1712.03890">DeepConf: Automating Data Center Network Topologies Management with Machine Learning.</a></li>
      <li><sup>12</sup>sup><a href="https://arxiv.org/abs/1810.01963Learning">Scheduling Algorithms for Data Processing Clusters.</a></li>
    </ul>
	</section>
</div>
<div class="speaker_section">
	<div class="inner clearfix">
		<section class="main-content">
			<h2 id="speakers">Speakers</h2>
			<div class="speaker-bio">
				<div class="img-holder" style="background-image: url(/assets/images/speakers/jeff_dean.jpg)"></div>
				<div>
					<h3>Jeff Dean</h3>
					<h5 class="keynote-speaker">Keynote Speaker</h5>
					<p>
					    Senior Fellow, Google AI. Google Brain lead and co-founder. Co-designer and implementor of Tensorflow, MapReduce, BigTable, Spanner.
					</p>
				</div>
			</div>
			<div class="speaker-bio">
				<div>
					<h3>Other speakers TBD</h3>
				</div>
			</div>
		</section>
	</div>
</div>
<div class="organizers-section">
	<div class="inner clearfix">
		<section class="main-content">
			<h2>Organizing Committee</h2>
			<ul>
				<li><b>Anna Goldie</b>, Google Brain, <a href="https://twitter.com/annadgoldie">@annadgoldie</a></li>
				<li><b>Azalia Mirhoseini</b>, Google Brain, <a href="https://twitter.com/Azaliamirh">@Azaliamirh</a></li>
				<li><b>Jonathan Raiman</b>, OpenAI, <a href="https://twitter.com/jonathanrraiman">@jonathanrraiman</a></li>
				<li><b>Kevin Swersky</b>, Google Brain, <a href="https://twitter.com/kswersk">@kswersk</a></li>
				<li><b>Milad Hashemi</b>, Google, <a href="https://hps.ece.utexas.edu/people/miladh/">website</a></li>
				<li><b>Amir Yazdanbakhsh</b>, Google Research, <a href="https://www.cc.gatech.edu/~ayazdanb/">website</a></li>
				<li><b>Xinlei Xu</b>, NYU, <a href="https://twitter.com/MimeeXu">@MimeeXu</a></li>
			</ul>
			<!-- <h2>Program Committee</h2>
			<ul>
			</ul> -->
			<h2>Contact Us</h2>
			<p>
				Contact us at <a href="mailto:mlforsystems@googlegroups.com">mlforsystems@googlegroups.com</a>.
			</p>
		</section>
</div>
